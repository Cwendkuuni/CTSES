import os
import re
import numpy as np
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity

import torch
from transformers import AutoTokenizer, AutoModel

from openai import OpenAI, APIError, APIConnectionError


# ------------------------------------------------------------------------------------------------
# Raw Java test inputs (same as Section II in the paper)
# ------------------------------------------------------------------------------------------------

original_test = """/*\n * This file was automatically generated by EvoSuite\n * Thu Feb 08 13:51:06 GMT 2024\n */\n\npackage macaw.presentationLayer;\n\nimport org.junit.Test;\nimport static org.junit.Assert.*;\nimport static org.evosuite.runtime.EvoAssertions.*;\nimport java.awt.HeadlessException;\nimport macaw.presentationLayer.MacawWorkBench;\nimport macaw.system.SessionProperties;\nimport org.evosuite.runtime.EvoRunner;\nimport org.evosuite.runtime.EvoRunnerParameters;\nimport org.junit.runner.RunWith;\n\n@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = false) \npublic class MacawWorkBench_ESTest extends MacawWorkBench_ESTest_scaffolding {\n\n  @Test(timeout = 4000)\n  public void test0()  throws Throwable  {\n      String[] stringArray0 = new String[2];\n      stringArray0[0] = \"\";\n      stringArray0[1] = \"\";\n      // Undeclared exception!\n      try { \n        MacawWorkBench.main(stringArray0);\n        fail(\"Expecting exception: NoClassDefFoundError\");\n      \n      } catch(NoClassDefFoundError e) {\n         verifyException(\"macaw.businessLayer.User\", e);\n      }\n  }\n}"""

refactored_test = """ package macaw.presentationLayer;\n\nimport org.junit.Test;\nimport static org.junit.Assert.*;\nimport static org.evosuite.runtime.EvoAssertions.*;\nimport java.awt.HeadlessException;\nimport macaw.presentationLayer.MacawWorkBench;\nimport macaw.system.SessionProperties;\nimport org.evosuite.runtime.EvoRunner;\nimport org.evosuite.runtime.EvoRunnerParameters;\nimport org.junit.runner.RunWith;\n\n@RunWith(EvoRunner.class)\n@EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = false)\npublic class MacawWorkBench_ESTest extends MacawWorkBench_ESTest_scaffolding {\n\n    @Test(timeout = 4000)\n    public void testMainMethodThrowsNoClassDefFoundError() throws Throwable {\n        String[] stringArray = new String[2];\n        stringArray[0] = \"\";\n        stringArray[1] = \"\";\n        try {\n            MacawWorkBench.main(stringArray);\n            fail(\"Expecting exception: NoClassDefFoundError\");\n        } catch (NoClassDefFoundError e) {\n            // verifyException(\"macaw.businessLayer.User\", e);\n        }\n    }\n}"""


# ------------------------------------------------------------------------------------------------
# Preprocessing (remove comments + blank lines)
# ------------------------------------------------------------------------------------------------

def clean_code(code: str) -> str:
    code = re.sub(r"//.*", "", code)
    code = re.sub(r"/\*.*?\*/", "", code, flags=re.DOTALL)
    return "\n".join([line for line in code.split("\n") if line.strip()])


# ------------------------------------------------------------------------------------------------
# CodeBERT and GraphCodeBERT Similarity
# ------------------------------------------------------------------------------------------------

def get_transformer_embedding(text: str, model_name: str) -> np.ndarray:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    model.eval()
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True).to(device)
    with torch.no_grad():
        outputs = model(**inputs)
    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()


# ------------------------------------------------------------------------------------------------
# OpenAI Embedding (requires .env file with OPENAI_API_KEY)
# ------------------------------------------------------------------------------------------------

def get_openai_embedding(text: str) -> np.ndarray:
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("Missing OPENAI_API_KEY in .env file")
    client = OpenAI(api_key=api_key)

    try:
        response = client.embeddings.create(
            input=text,
            model="text-embedding-3-small"
        )
        return np.array(response.data[0].embedding)
    except (APIError, APIConnectionError) as e:
        print(f"[OpenAI ERROR] {e}")
        return None


# ------------------------------------------------------------------------------------------------
# Cosine Similarity Computation
# ------------------------------------------------------------------------------------------------

def compute_cosine_similarity(emb1: np.ndarray, emb2: np.ndarray) -> float:
    return float(cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0])


# ------------------------------------------------------------------------------------------------
# Main Execution
# ------------------------------------------------------------------------------------------------

def main():
    print("=" * 80)
    print("Evaluating cosine similarity between EvoSuite and GPT-4o refactored test")
    print("=" * 80)

    original = clean_code(original_test)
    refactored = clean_code(refactored_test)

    print("\n[CodeBERT] Computing embeddings...")
    emb_codebert_orig = get_transformer_embedding(original, "microsoft/codebert-base")
    emb_codebert_ref = get_transformer_embedding(refactored, "microsoft/codebert-base")
    sim_codebert = compute_cosine_similarity(emb_codebert_orig, emb_codebert_ref)
    print(f"Cosine Similarity (CodeBERT)        : {sim_codebert:.4f}")

    print("\n[GraphCodeBERT] Computing embeddings...")
    emb_graphcodebert_orig = get_transformer_embedding(original, "microsoft/graphcodebert-base")
    emb_graphcodebert_ref = get_transformer_embedding(refactored, "microsoft/graphcodebert-base")
    sim_graphcodebert = compute_cosine_similarity(emb_graphcodebert_orig, emb_graphcodebert_ref)
    print(f"Cosine Similarity (GraphCodeBERT)   : {sim_graphcodebert:.4f}")

    print("\n[OpenAI] Computing embeddings...")
    emb_openai_orig = get_openai_embedding(original)
    emb_openai_ref = get_openai_embedding(refactored)
    if emb_openai_orig is not None and emb_openai_ref is not None:
        sim_openai = compute_cosine_similarity(emb_openai_orig, emb_openai_ref)
        print(f"Cosine Similarity (OpenAI)          : {sim_openai:.4f}")
    else:
        print("OpenAI embedding failed or skipped.")

    print("=" * 80)


if __name__ == "__main__":
    main()
